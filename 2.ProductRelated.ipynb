{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "import heapq\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "remvwords = stopwords.words('english')\n",
    "# newdata=pd.read_csv('./data/manualdata_remvname.csv')\n",
    "qsword=['not','in','t']\n",
    "# qsword=['what','who','when','why','where','whom','which','how','do','does','can','could','will','is','am','were','was','are','have','has','had',\n",
    "#        'did','if','most','don','don\\'t','should']\n",
    "remv = ['the','these','it','a','an','them','to']\n",
    "re_words = [x for x in remvwords if x not in qsword]\n",
    "re_words.append('mendeley')\n",
    "cos = metrics.pairwise.cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cosine similarity\n",
    "edu_qso = pd.read_csv('./data/newcla2ans.csv')\n",
    "edu_qso=edu_qso[['title','link']]\n",
    "edu_qso = edu_qso.iloc[:,:]\n",
    "edu_qs=edu_qso\n",
    "# edu_vect = TfidfVectorizer(ngram_range=(1,3),stop_words=re_words).fit(edu_qs['title'])\n",
    "# edu_data = edu_vect.transform(edu_qs['title'])\n",
    "# cla_2_qs = newdata.loc[newdata['label']==2]\n",
    "# cla_2_qs = edu_vect.transform(cla_2_qs['qs'])\n",
    "# def cosQA(query):\n",
    "#     qs_vec=edu_vect.transform([query])\n",
    "#     x = [cos(qs_vec,edu_data[i]) for i in range(0,303)]\n",
    "#     index=x.index(max(x))\n",
    "#     return edu_qs[index]['title']\n",
    "# edu_qs.to_csv('./data/edu_answer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_ans=pd.read_csv('./data/newcla2ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "tokenizer = nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosQA(query):\n",
    "#     query = tokenizer(query)\n",
    "#     query = [lemmatizer.lemmatize(x) for x in query]\n",
    "#     query = ''.join(query)\n",
    "    qs_vec=edu_vect.transform([query])\n",
    "    x = [cos(qs_vec,edu_data[i]) for i in range(len(edu_qs['title']))]\n",
    "    index=x.index(max(x))\n",
    "    return edu_qs[index]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(query):\n",
    "    query = query.lower()\n",
    "    query = tokenizer(query)\n",
    "    query = [word for word in query if word not in re_words]\n",
    "    query = [word for word in query if word.isalpha()]\n",
    "    query = [lemmatizer.lemmatize(x) for x in query]\n",
    "    query = ' '.join(query)\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(edu_qs['title'])):\n",
    "    edu_qs['title'][i] = cleanText(edu_qs['title'][i])\n",
    "edu_vect = TfidfVectorizer(ngram_range=(1,2),stop_words=re_words).fit(edu_qs['title'])\n",
    "edu_data = edu_vect.transform(edu_qs['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(edu_vect,open('./question_classifier/type2ans_vect.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_2ans = edu_vect\n",
    "def type2ans(query):\n",
    "    query = query.lower()\n",
    "    query = nltk.tokenize.word_tokenize(query)\n",
    "    query = [word for word in query if word.isalpha()]\n",
    "    query = [lemmatizer.lemmatize(x) for x in query]\n",
    "    query = ' '.join(query)\n",
    "    v = vect_2ans.transform([query])\n",
    "    x = [float(cos(v,edu_data[i])) for i in range(len(edu_qs['title']))]\n",
    "    if any(x):\n",
    "        index = np.argpartition(x,[-1,-2,-3,-4,-5])[-5:]\n",
    "        index = index[::-1]\n",
    "        print(index)\n",
    "        print(x[index[0]])\n",
    "        print(x[index[1]])\n",
    "        print(x[index[2]])\n",
    "        print(x[index[3]])\n",
    "        print(x[index[4]])\n",
    "        res_ind = 0\n",
    "        for i in index:\n",
    "            res_ind +=1\n",
    "            ans=np.array(edu_qso.iloc[[i]]).tolist()\n",
    "            ans = ans[0]\n",
    "            title = ans[0]\n",
    "            link = ans[1]\n",
    "            # title = edu_qso.iloc[[i]][0]\n",
    "            # link = edu_qso.iloc[[i]][1]\n",
    "            print(res_ind,title,link)\n",
    "    else:\n",
    "        st.write('result','no answer found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'ios'\n",
    "# query = tokenizer(query)\n",
    "# query = [lemmatizer.lemmatize(x) for x in query]\n",
    "# query = ' '.join(query)\n",
    "query = cleanText(query)\n",
    "v = edu_vect.transform([query])\n",
    "x = [float(cos(v,edu_data[i])) for i in range(len(edu_qs['title']))]\n",
    "if any(x):\n",
    "#     for i in heapq.nlargest(3,x):\n",
    "#         index.append(x.index(i))\n",
    "    index = np.argpartition(x,[-1,-2,-3,-4,-5])[-5:]\n",
    "    index = index[::-1]\n",
    "    for i in index:\n",
    "        print(np.array(edu_qso.iloc[[i]]).tolist())\n",
    "else:\n",
    "    print('no answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_test = pd.read_csv('./data/class2test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',1000,'display.width',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(class2_test['question'])):\n",
    "    class2_test['question'][i] = cleanText(class2_test['question'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2=[]\n",
    "score=[]\n",
    "for i in class2_test['question']:\n",
    "    query = i\n",
    "    v = edu_vect.transform([i])\n",
    "#     x = [cos(v,edu_data[i]) for i in range(len(edu_qs['title']))]\n",
    "    x = [float(cos(v,edu_data[i])) for i in range(len(edu_qs['title']))]\n",
    "#     if any(x):\n",
    "#         index = np.argpartition(x,-5)[-5:]\n",
    "#         index = index[::-1]\n",
    "#         res_ind = 0\n",
    "#         for i in index:\n",
    "#             res_ind +=1\n",
    "#             ans=np.array(edu_qso.iloc[[i]]).tolist()\n",
    "#             ans = ans[0]\n",
    "#             title = ans[0]\n",
    "#             link = ans[1]\n",
    "#             # title = edu_qso.iloc[[i]][0]\n",
    "#             # link = edu_qso.iloc[[i]][1]\n",
    "#             print(res_ind,title,link)\n",
    "    if any(x):\n",
    "#         index = [x.index(i) for i in heapq.nlargest(10, x)]\n",
    "        index = np.argpartition(x,[-1,-2,-3,-4,-5])[-5:]\n",
    "        index = index[::-1]\n",
    "        index = [ind for ind in index if x[ind]>0.306]\n",
    "        score.append([x[i] for i in index])\n",
    "        ans=[]\n",
    "#         single_query = []\n",
    "#         single_query = pd.DataFrame(single_query)\n",
    "        for i in index:\n",
    "#             single_query = pd.concat([single_query,edu_qso.iloc[[i]]],axis=1)\n",
    "            ans.append(for_ans.iloc[[i],1:].title)\n",
    "#             ans.append(np.array(for_ans.iloc[[i]]).tolist()[0][1:])\n",
    "        res_2.append(ans)\n",
    "#         res_2 = pd.concat([res_2,single_query],axis=0)\n",
    "    else:\n",
    "        res_2.append('no answer')\n",
    "        score.append(0)\n",
    "#         i = 'no answer'\n",
    "#         res_2 = pd.concat([res_2,pd.Series(i)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_2_res = pd.concat([class2_test,pd.Series(res_2)],axis=1)\n",
    "res_total = pd.DataFrame({'answer':res_2,'score':score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = cla2['answer'].str.split(',',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla2_test = pd.read_csv('./data/class2test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla2=pd.DataFrame({'question':cla2_test['question'],'answer':res_total['answer'],'score':res_total['score']})\n",
    "cla2.to_csv('./result/cla2ansthres.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1=[x for x in score if x!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer amount/how many data points\n",
    "noans=0\n",
    "one=0\n",
    "two=0\n",
    "three=0\n",
    "four=0\n",
    "five=0\n",
    "for i in score1:\n",
    "    if len(i)==0:\n",
    "        noans+=1\n",
    "    elif len(i)==1:\n",
    "        one +=1\n",
    "    elif len(i)==2:\n",
    "        two +=1\n",
    "    elif len(i)==3:\n",
    "        three+=1\n",
    "    elif len(i)==4:\n",
    "        four+=1\n",
    "    else: \n",
    "        five+=1\n",
    "print(noans, one,two,three,four,five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####DCG score\n",
    "scores = pd.read_csv('./data/newdcg_correctorder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscores=scores.iscore\n",
    "scores = scores.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[]\n",
    "si=[]\n",
    "for i,j in zip(scores,iscores):\n",
    "    s1=[]\n",
    "    s2=[]\n",
    "    for x in (0,2,4,6,8):\n",
    "        s1.append(int(i[x]))\n",
    "        s2.append(int(j[x]))\n",
    "    si.append(s2)\n",
    "    s.append(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "dcg_s=[]\n",
    "for i in s:\n",
    "    dcg = i[0]+(i[1]/np.log2(2))+(i[2]/np.log2(3))+(i[3]/np.log2(4))+(i[4]/np.log2(5))\n",
    "    dcg_s.append(dcg)\n",
    "    total += dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nDCG =DCG/IDCG\n",
    "total = 0\n",
    "dcg_s=[]\n",
    "for i,j in zip(s,si):\n",
    "    dcg = i[0]+(i[1]/np.log2(2))+(i[2]/np.log2(3))+(i[3]/np.log2(4))+(i[4]/np.log2(5))\n",
    "    idcg = j[0]+(j[1]/np.log2(2))+(j[2]/np.log2(3))+(j[3]/np.log2(4))+(j[4]/np.log2(5))\n",
    "    ndcg=dcg/idcg\n",
    "    dcg_s.append(ndcg)\n",
    "    total += ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcg_o=2+(2/np.log2(2))+(2/np.log2(3))+(2/np.log2(4))+(2/np.log2(5))\n",
    "dcg_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "th=[]\n",
    "for i,j in zip(score,s):\n",
    "    if i == 0 :\n",
    "        i=[0,0,0,0,0]\n",
    "        for x in range(0,5):\n",
    "            th.append([round(i[x],3),j[x]])\n",
    "    else:\n",
    "        for x in range(0,5):\n",
    "            th.append([round(i[x],3),j[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.array(th).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thp=pd.DataFrame({'score':th[0],'dcg':th[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=[]\n",
    "bs=[]\n",
    "ss=[]\n",
    "threshold = 0.0\n",
    "for i in range(0,1000):\n",
    "    x = thp[thp.score>threshold]['dcg'].value_counts() \n",
    "#     if len(x) == 3:\n",
    "#         x = x\n",
    "    gs.append([threshold,x[2]]) \n",
    "    try:\n",
    "        x[0]\n",
    "    except KeyError:\n",
    "        bs.append([threshold,0])\n",
    "    else:\n",
    "        bs.append([threshold,x[0]])\n",
    "    try:\n",
    "        x[1]\n",
    "    except KeyError:\n",
    "        ss.append([threshold,0])\n",
    "    else:\n",
    "        ss.append([threshold,x[1]])\n",
    "#     elif len(x) == 2:\n",
    "#         gs.append([threshold,x[0]])\n",
    "#         bs.append([threshold,0])\n",
    "#     else:\n",
    "#         gs.append([threshold,x[0]])\n",
    "#         bs.append([threshold,0])\n",
    "\n",
    "    threshold += 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=np.array(gs).T\n",
    "bs=np.array(bs).T\n",
    "ss=np.array(ss).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.0,1.0,.001)\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.xticks(x)\n",
    "plt.plot(x,gs[1],linewidth=2.5,label = 'Good Answer')\n",
    "plt.plot(x,bs[1],'g',label = 'Bad Answer')\n",
    "plt.plot(x,ss[1],'r',label = 'soso Answer')\n",
    "plt.grid()\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp=[]\n",
    "gr=[]\n",
    "for i in range(0,1000):\n",
    "    precision = (gs[1][i]+ss[1][i])/(gs[1][i]+ss[1][i]+bs[1][i])\n",
    "    recall = (gs[1][i]+ss[1][i])/(gs[1][1]+ss[1][1])\n",
    "    gp.append(precision)\n",
    "    gr.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.0,1.0,.001)\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.xticks(x)\n",
    "plt.plot(x,gp,linewidth=2.5,label = 'precision')\n",
    "plt.plot(x,gr,'g',label = 'recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
