{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics\n",
    "import sklearn.metrics as metrics\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqs_set = pd.read_csv('./data/manualdata_withoutqs.csv')\n",
    "qs_set = pd.read_csv('./data/qs_classify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "tokenizer = nltk.word_tokenize\n",
    "def cleanText(query):\n",
    "    query = query.lower()\n",
    "    query = tokenizer(query)\n",
    "#     query = [word for word in query if word.isalpha()]\n",
    "    query = [lemmatizer.lemmatize(x) for x in query]\n",
    "    query = ' '.join(query)\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nqs_set['qs'])):\n",
    "    nqs_set['qs'][i] = cleanText(nqs_set['qs'][i])\n",
    "for i in range(len(qs_set['qs'])):\n",
    "    qs_set['qs'][i] = cleanText(qs_set['qs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nqs\n",
    "vect_nqs = TfidfVectorizer(ngram_range=(1,3),stop_words = re_words).fit(nqs_set['qs'])\n",
    "pickle.dump(vect_nqs,open('./question_classifier/vect_query.pickle','wb'))\n",
    "trainset, testset, y_train, y_test = train_test_split(nqs_set['qs'], nqs_set['label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v=vect_nqs.transform(trainset)\n",
    "test_v=vect_nqs.transform(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = SVC(kernel='linear', probability = True,C=1.5)\n",
    "model_s.fit(train_v,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model_s.predict(test_v)\n",
    "accuracy_score(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model_s.predict(train_v)\n",
    "accuracy_score(pre,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "dirs='question_classifier'\n",
    "if not os.path.exists(dirs):\n",
    "    os.makedirs(dirs)\n",
    "joblib.dump(model_s, dirs+'/query_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qs\n",
    "vect_qs = TfidfVectorizer(ngram_range=(1,3),stop_words = remvwords).fit(qs_set['qs'])\n",
    "pickle.dump(vect_qs,open('./question_classifier/vect_qs.pickle','wb'))\n",
    "trainset, testset, y_train, y_test = train_test_split(qs_set['qs'], qs_set['label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v=vect_qs.transform(trainset)\n",
    "test_v=vect_qs.transform(testset)\n",
    "model_s = SVC(kernel='linear', probability = True,C=1.5)\n",
    "model_s.fit(train_v,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model_s.predict(test_v)\n",
    "accuracy_score(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model_s.predict(train_v)\n",
    "accuracy_score(pre,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "dirs='question_classifier'\n",
    "if not os.path.exists(dirs):\n",
    "    os.makedirs(dirs)\n",
    "joblib.dump(model_s, dirs+'/qs_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
